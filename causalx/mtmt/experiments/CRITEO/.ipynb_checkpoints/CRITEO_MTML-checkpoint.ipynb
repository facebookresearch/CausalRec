{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1125669d-ef2b-484b-91d2-abe3e42dd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Importing\n",
    "import gc, os, csv\n",
    "from catenets.models.jax import TNet, SNet1,SNet2,DRNet\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import sklift\n",
    "from sklift.metrics import uplift_auc_score\n",
    "\n",
    "sys.path.append(os.path.abspath('../../data/simulation'))\n",
    "from utils import tr_te_split,gen_1d_data, backdoor_dgp, frontdoor_dgp, instrument_dgp, simulated_study_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c1ab3-04cd-447f-b514-7f05dc3d63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f6c8fc-4c4c-4170-97ee-8ba4105cde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-layer MLP - Experts\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Two-layer MLP - Gates\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(Gate, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d1a3a6-fc16-4210-ad79-698980d630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOE\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, expert_output_dim, num_experts, num_tasks):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim, expert_output_dim) for _ in range(num_experts)])\n",
    "        self.gates = nn.ModuleDict({\n",
    "            f\"task_{task}_treatment_{treatment}\": Gate(input_dim, hidden_dim, num_experts)\n",
    "            for task in range(num_tasks) for treatment in range(2)\n",
    "        })\n",
    "        self.task_heads = nn.ModuleDict({\n",
    "            f\"task_{task}_treatment_{treatment}\": nn.Linear(expert_output_dim, 1)\n",
    "            for task in range(num_tasks) for treatment in range(2)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)  # Shape: (batch_size, expert_output_dim, num_experts)\n",
    "        outputs = {}\n",
    "\n",
    "        for key, gate in self.gates.items():\n",
    "            gate_weights = gate(x)  # Shape: (batch_size, num_experts)\n",
    "            gate_weights = gate_weights.unsqueeze(1)  # Shape: (batch_size, 1, num_experts)\n",
    "            mixture_output = torch.bmm(expert_outputs, gate_weights.transpose(1, 2)).squeeze(2)  # Shape: (batch_size, expert_output_dim)\n",
    "            task_output = self.task_heads[key](mixture_output)  # Shape: (batch_size, 1)\n",
    "            outputs[key] = task_output\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc4456-3c40-4f91-8386-e6fdc4c48a95",
   "metadata": {},
   "source": [
    "## Simple MTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8534fc-b49d-4d48-9811-ddcfd805a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "criteo_data_path = \"/data/home/yilingliu/MTML/experiments/CRITEO/criteo-uplift-v2.1.csv\"\n",
    "data = pd.read_csv(criteo_data_path)\n",
    "\n",
    "# Preprocess data\n",
    "X = data.drop(columns=[\"treatment\", \"visit\", \"conversion\",\"exposure\"]).values\n",
    "A = data[\"treatment\"].values\n",
    "Y = data[\"visit\"].values\n",
    "C = data[\"conversion\"].values\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "C_tensor = torch.tensor(C, dtype=torch.float32)\n",
    "\n",
    "# Train-Test Split (80-20%)\n",
    "N = len(X)\n",
    "split = np.random.choice(np.array([True, False]), N, replace=True, p=np.array([0.8, 0.2]))\n",
    "\n",
    "X_train, X_test = X[split], X[~split]\n",
    "A_train, A_test = A[split], A[~split]\n",
    "Y_train, Y_test = Y[split], Y[~split]\n",
    "C_train, C_test = C[split], C[~split]\n",
    "\n",
    "# Convert train data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "A_train_tensor = torch.tensor(A_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "C_train_tensor = torch.tensor(C_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d039521-36db-4fa0-b6de-730cb4a9c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch training\n",
    "batch_size = 512\n",
    "dataset = TensorDataset(X_train_tensor, A_train_tensor, Y_train_tensor, C_train_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 16 #32\n",
    "expert_output_dim = 16\n",
    "num_experts = 10\n",
    "num_tasks = 2\n",
    "\n",
    "model = MixtureOfExperts(input_dim, hidden_dim, expert_output_dim, num_experts, num_tasks)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for uplift modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f097d-d3e3-4d2a-bf84-fdedcdd9a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with batches\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for X_batch, A_batch, Y_batch, C_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = 0\n",
    "        \n",
    "        # Compute loss for the entire batch more efficiently\n",
    "        treatment_mask_0 = A_batch == 0\n",
    "        treatment_mask_1 = A_batch == 1\n",
    "        \n",
    "        y_true_0 = Y_batch[treatment_mask_0]\n",
    "        y_true_1 = Y_batch[treatment_mask_1]\n",
    "        c_true_0 = C_batch[treatment_mask_0]\n",
    "        c_true_1 = C_batch[treatment_mask_1]\n",
    "        \n",
    "        if y_true_0.numel() > 0:\n",
    "            y_pred_0 = outputs[\"task_0_treatment_0\"][treatment_mask_0]\n",
    "            loss += loss_fn(y_pred_0.squeeze(), y_true_0)\n",
    "            c_pred_0 = outputs[\"task_1_treatment_0\"][treatment_mask_0]\n",
    "            loss += loss_fn(c_pred_0.squeeze(), c_true_0)\n",
    "        \n",
    "        if y_true_1.numel() > 0:\n",
    "            y_pred_1 = outputs[\"task_0_treatment_1\"][treatment_mask_1]\n",
    "            loss += loss_fn(y_pred_1.squeeze(), y_true_1)\n",
    "            c_pred_1 = outputs[\"task_1_treatment_1\"][treatment_mask_1]\n",
    "            loss += loss_fn(c_pred_1.squeeze(), c_true_1)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f46ad-362b-4543-b92b-7741a6ee880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with the Mixture of Experts model on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "\n",
    "# Calculate AUUC for CRITEO-UPLIFT\n",
    "visit_preds_0 = outputs[\"task_0_treatment_0\"].detach().numpy().flatten()\n",
    "visit_preds_1 = outputs[\"task_0_treatment_1\"].detach().numpy().flatten()\n",
    "conversion_preds_0 = outputs[\"task_1_treatment_0\"].detach().numpy().flatten()\n",
    "conversion_preds_1 = outputs[\"task_1_treatment_1\"].detach().numpy().flatten()\n",
    "\n",
    "uplift_visit = visit_preds_1 - visit_preds_0\n",
    "uplift_conversion = conversion_preds_1 - conversion_preds_0\n",
    "\n",
    "auuc_visit = roc_auc_score(Y_test, uplift_visit)\n",
    "auuc_conversion = roc_auc_score(C_test, uplift_conversion)\n",
    "\n",
    "print(\"AUUC for Visit Uplift:\", auuc_visit)\n",
    "print(\"AUUC for Conversion Uplift:\", auuc_conversion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98836492-b64c-44cb-b18c-3e42cd0ced26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized AUUC\n",
    "auuc_visit = uplift_auc_score(Y_test, uplift_visit, A_test)\n",
    "auuc_conversion = uplift_auc_score(C_test, uplift_conversion, A_test)\n",
    "\n",
    "print(\"Normalized AUUC for Visit Uplift:\", auuc_visit)\n",
    "print(\"Normalized AUUC for Conversion Uplift:\", auuc_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d738f-2528-4e32-b2c0-b26aab2fc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized AUUC\n",
    "auuc_visit = uplift_auc_score(Y_test, uplift_visit, A_test)\n",
    "auuc_conversion = uplift_auc_score(C_test, uplift_conversion, A_test)\n",
    "\n",
    "print(\"Normalized AUUC for Visit Uplift:\", auuc_visit)\n",
    "print(\"Normalized AUUC for Conversion Uplift:\", auuc_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62f11f10-25d4-4874-b36c-367388fc2459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUUC from causalML\n",
      " uplift_score    0.444444\n",
      "Random          0.483333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from causalml.metrics import auuc_score\n",
    "from sklift.metrics import uplift_auc_score\n",
    "\n",
    "data = {\n",
    "    'treatment': [0, 1, 0, 1, 0, 1, 0, 1],\n",
    "    'outcome': [0, 1, 0, 1, 0, 1, 0, 0],\n",
    "    'uplift_score': [0.1, 0.9, 0.2, 0.8, 0.3, 0.7, 0.4, 0.5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate AUUC\n",
    "auuc = auuc_score(df, outcome_col='outcome', treatment_col='treatment', score_col='uplift_score',normalize=True)\n",
    "\n",
    "print(\"AUUC from causalML\\n\",auuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3efa6467-10f7-4a82-8724-fb894626a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUUC from sklift\n",
      " 0.21428571428571427\n"
     ]
    }
   ],
   "source": [
    "auuc_sklift = uplift_auc_score(data['outcome'], data['uplift_score'], data['treatment'])\n",
    "print(\"AUUC from sklift\\n\",auuc_sklift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c2711-ca8a-4f25-af40-caeebe0dfe50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
