{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1125669d-ef2b-484b-91d2-abe3e42dd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "# Importing\n",
    "import gc, os, csv\n",
    "from catenets.models.jax import TNet, SNet1,SNet2,DRNet\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../data/simulation'))\n",
    "from utils import tr_te_split,gen_1d_data, backdoor_dgp, frontdoor_dgp, instrument_dgp, simulated_study_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929c1ab3-04cd-447f-b514-7f05dc3d63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f6c8fc-4c4c-4170-97ee-8ba4105cde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the two-layer MLP for Experts\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the two-layer MLP for Gates\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
    "        super(Gate, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d1a3a6-fc16-4210-ad79-698980d630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Mixture of Experts Model\n",
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, expert_output_dim, num_experts, num_tasks):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim, expert_output_dim) for _ in range(num_experts)])\n",
    "        self.gates = nn.ModuleDict({\n",
    "            f\"task_{task}_treatment_{treatment}\": Gate(input_dim, hidden_dim, num_experts)\n",
    "            for task in range(num_tasks) for treatment in range(2)\n",
    "        })\n",
    "        self.task_heads = nn.ModuleDict({\n",
    "            f\"task_{task}_treatment_{treatment}\": nn.Linear(expert_output_dim, 1)\n",
    "            for task in range(num_tasks) for treatment in range(2)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)  # Shape: (batch_size, expert_output_dim, num_experts)\n",
    "        outputs = {}\n",
    "\n",
    "        for key, gate in self.gates.items():\n",
    "            gate_weights = gate(x)  # Shape: (batch_size, num_experts)\n",
    "            gate_weights = gate_weights.unsqueeze(1)  # Shape: (batch_size, 1, num_experts)\n",
    "            mixture_output = torch.bmm(expert_outputs, gate_weights.transpose(1, 2)).squeeze(2)  # Shape: (batch_size, expert_output_dim)\n",
    "            task_output = self.task_heads[key](mixture_output)  # Shape: (batch_size, 1)\n",
    "            outputs[key] = task_output\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc4456-3c40-4f91-8386-e6fdc4c48a95",
   "metadata": {},
   "source": [
    "## Simple MTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8534fc-b49d-4d48-9811-ddcfd805a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 615.260578204424\n",
      "Epoch 100, Loss: 29.127009046383392\n",
      "Epoch 200, Loss: 24.779542154226547\n",
      "Epoch 300, Loss: 22.635187836793754\n",
      "Epoch 400, Loss: 21.42100841571123\n",
      "Epoch 500, Loss: 20.283767030598263\n",
      "Epoch 600, Loss: 19.477974833586277\n",
      "Epoch 700, Loss: 18.849482925656513\n",
      "Epoch 800, Loss: 18.333885404544\n"
     ]
    }
   ],
   "source": [
    "# Download Criteo dataset\n",
    "criteo_url = \"https://criteo.com/wp-content/uploads/2021/06/criteo-uplift-v2.1.csv.zip\"\n",
    "criteo_zip_path = \"criteo_uplift.zip\"\n",
    "criteo_extract_path = \"criteo_uplift\"\n",
    "\n",
    "if not os.path.exists(criteo_zip_path):\n",
    "    response = requests.get(criteo_url, stream=True)\n",
    "    with open(criteo_zip_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "if not os.path.exists(criteo_extract_path):\n",
    "    with zipfile.ZipFile(criteo_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(criteo_extract_path)\n",
    "\n",
    "# Load dataset\n",
    "criteo_data_path = os.path.join(criteo_extract_path, \"criteo-uplift-v2.1.csv\")\n",
    "data = pd.read_csv(criteo_data_path)\n",
    "\n",
    "# Preprocess data\n",
    "X = data.drop(columns=[\"treatment\", \"visit\", \"conversion\"]).values\n",
    "A = data[\"treatment\"].values\n",
    "Y = data[\"visit\"].values\n",
    "C = data[\"conversion\"].values\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "C_tensor = torch.tensor(C, dtype=torch.float32)\n",
    "\n",
    "# Train-Test Split (80-20%)\n",
    "N = len(X)\n",
    "split = np.random.choice(np.array([True, False]), N, replace=True, p=np.array([0.8, 0.2]))\n",
    "\n",
    "X_train, X_test = X[split], X[~split]\n",
    "A_train, A_test = A[split], A[~split]\n",
    "Y_train, Y_test = Y[split], Y[~split]\n",
    "C_train, C_test = C[split], C[~split]\n",
    "\n",
    "# Convert train data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "A_train_tensor = torch.tensor(A_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "C_train_tensor = torch.tensor(C_train, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "batch_size = 64\n",
    "dataset = TensorDataset(X_train_tensor, A_train_tensor, Y_train_tensor, C_train_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 20\n",
    "expert_output_dim = 5\n",
    "num_experts = 3\n",
    "num_tasks = 2\n",
    "\n",
    "model = MixtureOfExperts(input_dim, hidden_dim, expert_output_dim, num_experts, num_tasks)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for uplift modeling\n",
    "\n",
    "# Training loop with batches\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for X_batch, A_batch, Y_batch, C_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = 0\n",
    "        \n",
    "        # Compute loss for each task and treatment using the treatment indicator A\n",
    "        for i in range(X_batch.size(0)):\n",
    "            treatment = int(A_batch[i].item())\n",
    "            y_key = f\"task_0_treatment_{treatment}\"\n",
    "            c_key = f\"task_1_treatment_{treatment}\"\n",
    "            \n",
    "            y_true_values = Y_batch[i].unsqueeze(0)\n",
    "            y_predicted_values = outputs[y_key][i]\n",
    "            loss += loss_fn(y_predicted_values, y_true_values)\n",
    "            \n",
    "            c_true_values = C_batch[i].unsqueeze(0)\n",
    "            c_predicted_values = outputs[c_key][i]\n",
    "            loss += loss_fn(c_predicted_values, c_true_values)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# Forward pass with the Mixture of Experts model on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "\n",
    "# Calculate AUUC for CRITEO-UPLIFT\n",
    "visit_preds_0 = outputs[\"task_0_treatment_0\"].detach().numpy().flatten()\n",
    "visit_preds_1 = outputs[\"task_0_treatment_1\"].detach().numpy().flatten()\n",
    "conversion_preds_0 = outputs[\"task_1_treatment_0\"].detach().numpy().flatten()\n",
    "conversion_preds_1 = outputs[\"task_1_treatment_1\"].detach().numpy().flatten()\n",
    "\n",
    "uplift_visit = visit_preds_1 - visit_preds_0\n",
    "uplift_conversion = conversion_preds_1 - conversion_preds_0\n",
    "\n",
    "auuc_visit = roc_auc_score(Y_test, uplift_visit)\n",
    "auuc_conversion = roc_auc_score(C_test, uplift_conversion)\n",
    "\n",
    "print(\"AUUC for Visit Uplift:\", auuc_visit)\n",
    "print(\"AUUC for Conversion Uplift:\", auuc_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ef000-4b42-41b2-b9c0-cb1ebe82d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass with the Mixture of Experts model on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor(X_test, dtype=torch.float32))\n",
    "\n",
    "# Extracting example outputs for causal estimation\n",
    "y_a_0 = outputs[\"task_0_treatment_0\"].detach().numpy().flatten()\n",
    "y_a_1 = outputs[\"task_0_treatment_1\"].detach().numpy().flatten()\n",
    "y_b_0 = outputs[\"task_1_treatment_0\"].detach().numpy().flatten()\n",
    "y_b_1 = outputs[\"task_1_treatment_1\"].detach().numpy().flatten()\n",
    "\n",
    "cate_pred_y = y_a_1 - y_a_0\n",
    "cate_pred_c = y_b_1 - y_b_0\n",
    "\n",
    "\n",
    "# Compute RMSE for the treatment effects predicted by model_y and model_c\n",
    "rmse_y = np.sqrt(mean_squared_error(Y_true_test_cate, cate_pred_y))\n",
    "rmse_c = np.sqrt(mean_squared_error(C_true_test_cate, cate_pred_c))\n",
    "\n",
    "print(\"RMSE for treatment effect by t_Y:\", rmse_y)\n",
    "print(\"RMSE for treatment effect by t_C:\", rmse_c)\n",
    "\n",
    "# Plotting for the last element in N\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Y_true_test_cate, cate_pred_y, alpha=0.5)\n",
    "plt.plot([Y_true_test_cate.min(), Y_true_test_cate.max()], [Y_true_test_cate.min(), Y_true_test_cate.max()], 'k--')\n",
    "plt.xlabel('True CATE')\n",
    "plt.ylabel('Predicted CATE ($t_Y$)')\n",
    "plt.title('True vs Predicted CATE (Model $t_Y$)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(C_true_test_cate, cate_pred_c, alpha=0.5)\n",
    "plt.plot([C_true_test_cate.min(), C_true_test_cate.max()], [C_true_test_cate.min(), C_true_test_cate.max()], 'k--')\n",
    "plt.xlabel('True CATE')\n",
    "plt.ylabel('Predicted CATE ($t_C$)')\n",
    "plt.title('True vs Predicted CATE (Model $t_C$)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
